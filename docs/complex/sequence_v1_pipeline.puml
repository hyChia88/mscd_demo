@startuml MSCD_Demo_Sequence_V1
!theme plain
title **V1 Pipeline -- Agent-Driven (ReAct + MCP)**

participant "run.py"              as RUN
participant "MCP Session\n(common/mcp.py)"  as MCP
participant "IFC MCP Server\n(ifc_server.py)" as IFC_SRV
participant "IFCEngine"           as ENG
participant "LangGraph\nReAct Agent"  as AGENT
participant "Gemini LLM"          as LLM
participant "VisualAligner\n(CLIP)" as CLIP
participant "Eval Runner\n(eval/runner.py)" as EVAL
participant "RQ2 Pipeline\n(rq2_schema/)"  as RQ2

activate RUN

== MCP Connection ==

RUN -> MCP : mcp_session(base_dir, env)
activate MCP
MCP -> IFC_SRV : spawn subprocess\n(stdio transport)
activate IFC_SRV
IFC_SRV -> ENG : IFCEngine(ifc_path)
ENG --> IFC_SRV : engine singleton
IFC_SRV --> MCP : FastMCP server ready
MCP -> IFC_SRV : session.list_tools()
IFC_SRV --> MCP : tool list:\nlist_available_spaces\nget_elements_by_storey\nsearch_elements_by_type\nget_element_details ...
MCP -> MCP : convert_mcp_to_langchain_tools()
MCP --> RUN : MCPContext(tools, tool_by_name)
deactivate MCP

RUN -> AGENT : create_react_agent(\nllm, tools, system_prompt)
AGENT --> RUN : agent_executor

== Per-Case Evaluation Loop ==

loop for each case in dataset
    RUN -> EVAL : run_one_scenario(scenario,\nagent_executor, engine)
    activate EVAL
    EVAL -> EVAL : format_scenario_input()\n(4D context + chat + query)

    EVAL -> AGENT : ainvoke({"messages": [user_input]})
    activate AGENT

    note right of AGENT
        **ReAct Loop** (multi-turn)
        LLM reasons -> selects tool ->
        executes -> observes -> repeats
    end note

    loop ReAct reasoning steps
        AGENT -> LLM : Reason over context\n+ available tools
        LLM --> AGENT : tool_call decision\n(name, args)

        alt IFC spatial query
            AGENT -> IFC_SRV : search_elements_by_type\n(ifc_class, storey_filter)
            IFC_SRV -> ENG : spatial_index lookup\nor Neo4j Cypher query
            ENG --> IFC_SRV : element list\n[{guid, name, type, storey}]
            IFC_SRV --> AGENT : JSON result (via MCP)

        else get element details
            AGENT -> IFC_SRV : get_element_details(guid)
            IFC_SRV -> ENG : extract Pset properties
            ENG --> IFC_SRV : {properties, geometry}
            IFC_SRV --> AGENT : JSON result (via MCP)

        else CLIP visual matching (if enabled)
            AGENT -> IFC_SRV : analyze_site_image(path)\nor match_image_to_elements()
            IFC_SRV -> CLIP : match_image_to_descriptions()
            CLIP --> IFC_SRV : ranked candidates\nwith confidence scores
            IFC_SRV --> AGENT : JSON result (via MCP)
        end

        AGENT -> LLM : Observation + reason next step
        LLM --> AGENT : next action or\nfinal answer
    end

    AGENT --> EVAL : response {messages[]}
    deactivate AGENT

    EVAL -> EVAL : parse_interpreter_output()\nextract GUIDs & names\ncompute_gt_matches()

    alt RQ2 category case
        EVAL -> RQ2 : extract_final_json()\nrun_rq2_postprocess()
        activate RQ2
        RQ2 -> RQ2 : Schema mapping\nJSON Schema validation\nDomain validation
        RQ2 --> EVAL : RQ2Result\n(passed, fill_rate)
        deactivate RQ2
    end

    EVAL --> RUN : EvalTrace\n(guid_match, latency,\ntool_steps, candidates)
    deactivate EVAL
end

deactivate IFC_SRV
deactivate RUN

@enduml
